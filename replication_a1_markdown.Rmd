---
title: "Replication Econometrics III -- A1"
author: "Calebe Piacentini and Giovanni"
date: "2024-01-25"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(dplyr)
library(quantmod)
library(forecast)
library(lubridate)
library(gt)
library(tibble)
library(knitr)
library(kableExtra)
```

## What do we need to replicate?

As exposed in the guidelines, we need to replicate all tables and figures **except** for the parts involving models RGM, VAR, RGMVAR, MDL1 and MDL2.

Altering table 2 from the paper to exclude these models, we have:

```{r models}
# Create the data frame
models_table <- data.frame(
 Description = c(
  "Time-series models", # 1
  "", # 2
  "", # 3
  "", # 4
  "Phillips curve (OLS)", # 5
  "", # 6
  "", # 7
  "", # 8
  "", # 9
  "", # 10
  "", # 11
  "", # 12
  "", # 13
  "", # 14
  "OLS term structure models", # 15
  "", # 16
  "", # 17
  "", # 18
  "", # 19
  "", # 20
  "", # 21
  "", # 22
  "", # 23
  "", # 24
  "", # 25
  "Inflation surveys", # 26
  "", # 27
  "", # 28
  "", # 29
  "", # 30
  "", # 31
  "", # 32
  "", # 33
  "" # 34
 ),
 Abbreviation = c(
  "ARMA", # 1
  "AR", # 2
  "RW", # 3
  "AORW", # 4
  "PC1", # 5
  "PC2", # 6
  "PC3", # 7
  "PC4", # 8
  "PC5", # 9
  "PC6", # 10
  "PC7", # 11
  "PC8", # 12
  "PC9", # 13
  "PC10", # 14
  "TS1", # 15
  "TS2", # 16
  "TS3", # 17
  "TS4", # 18
  "TS5", # 19
  "TS6", # 20
  "TS7", # 21
  "TS8", # 22
  "TS9", # 23
  "TS10", # 24
  "TS11", # 25
  "SPF1", # 26
  "SPF2", # 27
  "SPF3", # 28
  "LIV1", # 29
  "LIV2", # 30
  "LIV3", # 31
  "MICH1", # 32
  "MICH2", # 33
  "MICH3" # 34
 ),
 Specification = c(
  "ARMA(1,1)", # 1
  "Autoregressive model", # 2
  "Random walk on quarterly inflation", # 3
  "Random walk on annual inflation", # 4
  "INFL + GDPG", # 5
  "INFL + GAP1", # 6
  "INFL + GAP2", # 7
  "INFL + LSHR", # 8
  "INFL + UNEMP", # 9
  "INFL + XLI", # 10
  "INFL + XLI-2", # 11
  "INFL + FAC", # 12
  "INFL + GAP1 + LSHR", # 13
  "INFL + GAP2 + LSHR", # 14
  "INFL + GDPG + RATETS", # 15
  "INFL + GAP1 + RATETS", # 16
  "INFL + GAP2 + RATETS", # 17
  "INFL + LSHR + RATETS", # 18
  "INFL + UNEMP + RATETS", # 19
  "INFL + XLI + RATETS", # 20
  "INFL + XLI-2 + RATETS", # 21
  "INFL + FAC + RATETS", # 22
  "INFL + SPDTS", # 23
  "INFL + RATE + SPDTS", # 24
  "INFL + GDPG + RATE + SPDT", # 25
  "VAR(1) on RATE, SPD, INFL, GDPG", # 26
  "Linear bias-corrected SPF", # 27
  "Non-linear bias-corrected SPFLIV1", # 28
  "Livingston survey", # 29
  "Linear bias-corrected Livingston", # 30
  "Non-linear bias-corrected Livingston", # 31
  "Michigan survey", # 32
  "Linear bias-corrected Michigan", # 33
  "Non-linear bias-corrected Michigan" # 34
 )
)

knitr::kable(models_table)
```

First we'll replicate the authors work with similar data and then we'll do the same but for the Brazilian data.

## Loading Data

Data from the paper.

Part of the data (mainly from real data sources and when it comes from other papers) was gathered through the authors data replication kit (asked by e-mail).

We'll do the following procedure: first we gather data, save it to new files and then for each part we load the data again.

```{r, include=FALSE}
source("replication_a1_data-only.R", local = knitr::knit_global())
```

And now data from Brazil.

```{r, include=FALSE}
source("replication_a1_data_brazil.R", local = knitr::knit_global())
```

## Summary statistics

Here we replicate table 1 of Summary Statistics from the paper and the following figures.

First, we do it for the exactly the period of their analysis. It's worth noting that although their first year of analysis is 1952, PUXX only starts to have data at 1957 (even though they use data starting from 1958).

[summary statistics]

## Estimating the models

### Time-Series Models

Here we'll estimate the ARMA, AR, RW and AORW.

```{r time_series_models}

# 02 load dataframes used ------------------------

df_inflation_complete <- read.csv(file = "data/output/df_inflation_complete.csv")
df_inflation_authors <- read.csv(file = "data/output/df_inflation_authors.csv")
df_inflation_authors_yearly <- read.csv(file = "data/output/df_inflation_authors_yearly.csv")

# 03 models ------------------------------------

# Function to perform rolling window forecasting with ARMA(1,1) over years
rolling_forecast_arma <- function(data, series_name, order_ar=1, order_ma=1, initial_end=1985, final_date=2002, window_size=4, return_rmse=T) {
  # adding a forecast vector to store results
  forecasts <- numeric((final_date - initial_end)*window_size)
  
  # loop for the rolling window
  for (y in initial_end:(final_date-1)) {  # we take one out to don't count the last year
    train_data <- data %>% filter(group <= y)  # Use data up to the current index for training
    train_series <- train_data %>% .[series_name]
    
    # Fit ARMA(1,1) model: yt = mu + phi*yt-1 + epsilon_t + psi*epsilon_{t-1}
    arma_model <- arima(train_series, order = c(order_ar, 0, order_ma))
    # get coefficients + residuals
    phi <- arma_model$coef[1]
    psi <- arma_model$coef[2]
    mu <- arma_model$coef[3]
    residuals <- arma_model$residuals
    
    # Forecast for the next 4 quarters according to equation on paper
    forecast_q <- c()
    for (q in 1:4) {
      forecast_q[q] <- (1/(1-phi)) * (4 - (phi * (1-phi^4))/(1-phi)) * mu + ((phi * (1-phi^4))/(1-phi)) * train_series[nrow(train_series) - (q-1),] + (psi * (1-phi^4))/(1-phi) * residuals[nrow(train_series) - (q-1)]
    }
    
    # just making sure
    forecast_values <- as.numeric(forecast_q)
    # Store forecast values
    forecasts[((y - initial_end)*window_size + 1):((y - initial_end+1)*window_size)] <- forecast_values
  }
  
  # decide whether to return forecasts or root mean squared errors (RMSE)
  if (return_rmse) {
    # get data to validate forecasts
    test_series <- data %>% filter(group > initial_end) %>% .[series_name]
    rmse <- sqrt(sum((test_series - forecasts)^2, na.rm=T))
    return(rmse)
  } else{
    return(forecasts)
  }
}

# very similar to the last function, 
# with the difference that now we'll choose AR(p) recursively by SIC
rolling_forecast_ar_p <- function(data, series_name, initial_end=1985, final_date=2002, window_size=4, return_rmse=T) {
  # creating a forecast vector to store results
  forecasts <- numeric((final_date - initial_end)*window_size)
  
  # loop for the rolling window
  for (y in initial_end:(final_date-1)) {
    train_data <- data %>% filter(group <= y)  # Use data up to the current index for training
    train_series <- train_data %>% select(series_name)
    
    # find best ar order
    ar_order <- best_arma_order(train_series)
    # Fit AR(p) model
    arma_model <- stats::arima(train_series, order = c(ar_order, 0, 0))
    
    # Forecast for the next 4 quarters
    #  ... a little note: here we abstract from the way the paper is doing, since it would imply unecessary complexity (look at the equation for the quarterly forecast in page 1174)
    forecast_values <- as.numeric(forecast(arma_model, h = 4)$mean)
    # Store forecast values
    forecasts[((y - initial_end)*window_size + 1):((y - initial_end+1)*window_size)] <- forecast_values
  }
  
  # decide whether to return forecasts or root mean squared errors (RMSE)
  if (return_rmse) {
    # get data to validate forecasts
    test_series <- data %>% filter(group > initial_end) %>% .[series_name]
    rmse <- sqrt(sum((test_series - forecasts)^2, na.rm=T))
    return(rmse)
  } else{
    return(forecasts)
  }
}

# to find the best arma model based on some criteria (still don't contemplate ma orders or other info_criteria than BIC/SIC)
best_arma_order <- function(series, ar_until = 10, ma_order = 0, info_criteria = 'bic'){
  arma_models <- list()
  bic_arma <- c()
  for (p in 1:ar_until) {
    arma_models[[p]] <- arima(series, order = c(p, 0, ma_order))
    # BIC = SIC
    bic_arma[p] <- BIC(arma_models[[p]])
  }
  arma_best_order <- which(min(bic_arma) == bic_arma)
  return(arma_best_order)
}

# creates a matrix with (y*x) rows and (estats) columns
create_table_inflation_models <- function(values_estats, y, x, estats=c('relative_rmse', '1-lambda', 'hh_error', 'nw_error')){
  # values_stats should be a list of same size as the estats, each value being y*x size (in that order)
  # storing data for table
  table_paper <- matrix(NA, length(y)*length(x), length(estats))  # just for a single estimation period
  # prettify
  colnames(table_paper) <- estats
  names_inflation <- rep(y, each=length(x))
  names_models <- rep(x, length(y))
  rownames(table_paper) <- paste(names_inflation, names_models, sep=' | ')
  
  # adding values
  for (p in 1:length(estats)) {
    table_paper[,p] <- values_estats[[p]]
  }
  
  return(table_paper)
}

# running the functions
inflation_series <- df_inflation_authors %>% select(starts_with('inflation')) %>% colnames()

# loops

# defining vectors to store data
arma11_rmse1985 <- c()
arp_rmse <- c()
arma11_forecasts1985 <- list()

# 1985
for (x in 1:length(inflation_series)) {
  print(inflation_series[x])
  # first the simple rmse values for each inflation series
  arma11_rmse1985[x] <- rolling_forecast_arma(df_inflation_authors, inflation_series[x])
  arp_rmse[x] <- rolling_forecast_ar_p(df_inflation_authors, inflation_series[x])
  
  # we need also the forecasts of the arma11 model to run the lambda models
  arma11_forecasts1985[[inflation_series[x]]] <- rolling_forecast_arma(df_inflation_authors, inflation_series[x], return_rmse = F)
}

# printing info
arma11_rmse <- arma11_rmse1985
#
# a loop to get values in the way the table is constructed in the paper
just_rmse <- c()
relative_rmse <- c()
for (x in 1:length(arma11_rmse)) {
  just_rmse <- c(just_rmse, arma11_rmse[x], arp_rmse[x])
  relative_rmse_aux <- c(arma11_rmse[x], arp_rmse[x])
  relative_rmse <- c(relative_rmse, relative_rmse_aux)
}
values_estats <- list(just_rmse, relative_rmse)
table_ts <- create_table_inflation_models(values_estats, inflation_series, c('ARMA', 'AR'), c('RMSE', 'ARMA=1'))
print(table_ts)

# ---
# again for a new year
# ---

# todo: add option to pick the values 

arma11_rmse1995 <- c()
arp_rmse <- c()
arma11_forecasts1995 <- list()

# 1995
for (x in 1:length(inflation_series)) {
  print(inflation_series[x])
  # first the simple rmse values for each inflation series
  arma11_rmse1995[x] <- rolling_forecast_arma(df_inflation_authors, inflation_series[x], initial_end = 1995)
  arp_rmse[x] <- rolling_forecast_ar_p(df_inflation_authors, inflation_series[x])
  
  # we need also the forecasts of the arma11 model to run the lambda models
  arma11_forecasts1995[[inflation_series[x]]] <- rolling_forecast_arma(df_inflation_authors, inflation_series[x], return_rmse = F, initial_end = 1995)
}

# printing info
arma11_rmse <- arma11_rmse1995
#
# a loop to get values in the way the table is constructed in the paper
just_rmse <- c()
relative_rmse <- c()
for (x in 1:length(arma11_rmse)) {
  just_rmse <- c(just_rmse, arma11_rmse[x], arp_rmse[x])
  relative_rmse_aux <- c(arma11_rmse[x], arp_rmse[x])
  relative_rmse <- c(relative_rmse, relative_rmse_aux)
}
values_estats <- list(just_rmse, relative_rmse)
table_ts_1995 <- create_table_inflation_models(values_estats, inflation_series, c('ARMA', 'AR'), c('RMSE', 'ARMA=1'))
print(table_ts_1995)
```

### Phillips Curve (OLS) + Time Structure models


Here, we do a similar procedure as before for the time-series models, however, now we estimate the models using a simple OLS regression. As for the AR(p) model we'll dynamically choose the order of the regressors such that it minimizes the bayesian information criteria (BIC or SIC). Basically, the model we'll estimate goes as follows (for the training sample):

$$
\pi_{t+4,4} = \alpha + \beta'(L) X_t + \epsilon_{t+4,4}
$$
where $\pi_{t+4,4}$ is defined (annually) as previously, $\beta(L)$ is a filter for the variables in $X_t$ that includes the dependent variable (inflation) and another independent variable (some real activity measure, $y_{t+4,4}$). That means that if we have $L=2$, $\beta'(L) X_t$ will include $\pi_{t+3,4}$, $\pi_{t+2,4}$, $y_{t+3,4}$ and $y_{t+2,4}$.

Regarding the window of training and testing, we weren't able to identify whether the authors keep, as before, a rolling window or whether they now use a fixed one. Despite it would make sense to keep the previous approach, we choose to use a fixed window to keep with a conservative/simplicity take.

Moreover, since the process is basically the same as before for the term structure models, we just add them below, then printing the tables.

As previously, we first do for the 1985 period, then for 1995.

```{r phillips_term-structure1985}
# ---
# Load data ----
# ---

# df_inflation_complete <- read.csv("df_inflation_complete.csv")
df_inflation_authors <- read.csv("data/output/df_inflation_authors.csv")
df_realmeasures_authors <- read.csv("data/output/df_realmeasures_authors.csv")

# Prepare data
df_phillips <- df_inflation_authors %>%
  left_join(df_realmeasures_authors) %>% 
  tibble() %>%
  arrange(FirstDate)

# ---
# Functions ----
# ---

# a function just to lag our dataset
lag_df <- function(df, y, x, lag_until = 5) {
  models <- list()
  bic_models <- c()
  df_lag <- df
  
  # first we loop for the y variable
  for (p in 1:lag_until) {
    df_lag <- df_lag %>% 
      mutate(!!str_c('lag', p, '_', y) := lag(!!sym(y), p))
  }
  
  # then we check whether x is a vector and do the adequate operation 
  if (is.character(x) && length(x) == 1) {
    # If x is a single string, create lagged column for it
    for (p in 1:lag_until) {
      df_lag <- df_lag %>% 
        mutate(!!str_c('lag', p, '_', x) := lag(!!sym(x), p))
    }
  } else if (is.character(x) && length(x) > 1) {
    # If x is a character vector, create lagged columns for each element
    for (var in x) {
      for (p in 1:lag_until) {
        df_lag <- df_lag %>% 
          mutate(!!str_c('lag', p, '_', var) := lag(!!sym(var), p))
      }
    }
  }
  
  return(df_lag)
}

# a function to choose the best lag of the ols based on bic
best_lag_ols <- function(df_lag, y, lag_until=5, criteria='bic'){
  # defining relevant variables
  dependent_var <- y
  independent_var <- c()
  
  # variables to store
  models <- list()
  bic_models <- c()
  
  # loop of lags
  for (p in 1:lag_until) {
    independent_var_plus <- df_lag %>% select(starts_with(paste0('lag', p))) %>% colnames()
    independent_var <- c(independent_var, independent_var_plus)
    reg_formula <- formula(paste(dependent_var, '~', paste(independent_var, collapse=' + ')))
    models[[p]] <- lm(reg_formula, data=df_lag)
    bic_models[p] <- BIC(models[[p]])
  }
  
  # then find the best order
  best_order <- which(min(bic_models) == bic_models)
  
  return(models[[best_order[1]]])
}

# todo: use a rolling window?
# a function to predict for a ols model
ols_predict <- function(train_data, test_data, y, x, max_lag=5){
  # choose the best lag and returns the model
  model <- best_lag_ols(train_data, y, lag_until = max_lag)
  
  # forecast values
  forecast_values <- forecast(model, test_data)
  
  return(forecast_values$mean)
}

# creates a matrix with (y*x) rows and (estats) columns
create_table_inflation_models <- function(values_estats, y, x, estats=c('relative_rmse', '1-lambda', 'hh_error', 'nw_error')){
  # values_stats should be a list of same size as the estats, each value being y*x size (in that order)
  # storing data for table
  table_paper <- matrix(NA, length(y)*length(x), length(estats))  # just for a single estimation period
  # prettify
  colnames(table_paper) <- estats
  names_inflation <- rep(y, each=length(x))
  names_models <- rep(x, length(y))
  rownames(table_paper) <- paste(names_inflation, names_models, sep=' | ')
  
  # adding values
  for (p in 1:length(estats)) {
    table_paper[,p] <- values_estats[[p]]
  }
  
  return(table_paper)
}

# ---
# Run ----
# ---

# change here to change periods (either 1985 or 1995 yet)
initial_estimation_period <- 1985
arma11_rmse <- arma11_rmse1985
arma11_forecasts <- arma11_forecasts1985

# ---
## Phillips models ----
# ---

all_y <- df_phillips %>% select(starts_with('inflation')) %>% colnames()  # "inflation_punew" "inflation_puxhs" "inflation_puxx"  "inflation_pce"
x_phillips <- df_phillips %>% select(gdpg:fac) %>% colnames()  # "gdpg"            "gap1"            "gap2"            "unrate"          "lshr"            "xli"             "xli2"            "fac"

# todo: we need more one loop for the other group: 1995

# two loops, one for the dependent variable, other for the independent variable
rmse <- c()
lambda_phillips <- c()
hh_se_phillips <- c()
nw_se_phillips <- c()
for (y in all_y) {
  print(y)
  for (x in x_phillips) {
    print(x)
    # define all the dataframes relevant
    df_lag <- lag_df(df_phillips, y, x)
    train_data <- df_lag %>% filter(group <= initial_estimation_period)
    test_data <- df_lag %>% filter(group > initial_estimation_period)
    
    # get forecast
    forecast_values <- ols_predict(train_data, test_data, y, x)
    
    # todo: store the arma11 rmse from previous exercise
    # compute (relative) rmse
    rmse <- c(rmse, sqrt(sum((test_data[y] - forecast_values)^2, na.rm=T)))
    
    # compute 1-lambda
    arma11_forecasts_now <- arma11_forecasts[[y]]
    reg_formula_lambda <- formula(paste0(y, '~ arma11_forecasts_now + forecast_values'))
    model_lambda <- lm(reg_formula_lambda, data=test_data)
    lambda_phillips <- c(lambda_phillips ,coef(model_lambda)[3])
    # standard-error first with HH-error
    hh_se_phillips <- c(hh_se_phillips ,kernHAC(model_lambda, kernel = "Truncated")[3,3])
    # then with NW-error
    nw_se_phillips <- c(nw_se_phillips, NeweyWest(model_lambda)[3,3])
  }
}

# calculate the relative rmse to arma11
relative_rmse <- rmse/rep(arma11_rmse, each=length(x_phillips))
# define a list to pass to the function to create tables paper-like
values_estats <- list(relative_rmse, lambda_phillips, hh_se_phillips, nw_se_phillips)
table_ols <- create_table_inflation_models(values_estats, all_y, x_phillips)
print(table_ols)

# ---
# now do it for models with double x's
# ---
doublex_phillips <- list(c('gap1', 'lshr'), c('gap2', 'lshr'))
x_names <- sapply(doublex_phillips, function(x) paste(x, collapse=' + '))
x_now <- doublex_phillips
rmse <- c()
lambda_phillips <- c()
hh_se_phillips <- c()
nw_se_phillips <- c()
# loop
for (y in all_y) {
  print(y)
  for (x in x_now) {
    print(x)
    # define all the dataframes relevant
    df_lag <- lag_df(df_phillips, y, x)
    train_data <- df_lag %>% filter(group <= initial_estimation_period)
    test_data <- df_lag %>% filter(group > initial_estimation_period)
    
    # get forecast
    forecast_values <- ols_predict(train_data, test_data, y, x)
    
    # compute (relative) rmse
    rmse <- c(rmse, sqrt(sum((test_data[y] - forecast_values)^2, na.rm=T)))
    
    # compute 1-lambda
    arma11_forecasts_now <- arma11_forecasts[[y]]     
    reg_formula_lambda <- formula(paste0(y, '~ arma11_forecasts_now + forecast_values'))
    model_lambda <- lm(reg_formula_lambda, data=test_data)
    lambda_phillips <- c(lambda_phillips ,coef(model_lambda)[3])
    # standard-error first with HH-error
    hh_se_phillips <- c(hh_se_phillips ,kernHAC(model_lambda, kernel = "Truncated")[3,3])
    # then with NW-error
    nw_se_phillips <- c(nw_se_phillips, NeweyWest(model_lambda)[3,3])
  }
}

# calculate the relative rmse to arma11
relative_rmse <- rmse/rep(arma11_rmse, each=length(x_names))
# define a list to pass to the function to create tables paper-like
values_estats <- list(relative_rmse, lambda_phillips, hh_se_phillips, nw_se_phillips)
table_ols_2x <- create_table_inflation_models(values_estats, all_y, x_names)
print(table_ols_2x)

# ---
## Term Structure ----
# ---

# basically the same as before, plus rate

all_y <- df_phillips %>% select(starts_with('inflation')) %>% colnames()  # "inflation_punew" "inflation_puxhs" "inflation_puxx"  "inflation_pce"
x_phillips <- df_phillips %>% select(gdpg:fac) %>% colnames()  # "gdpg"            "gap1"            "gap2"            "unrate"          "lshr"            "xli"             "xli2"            "fac"
x_with_rate <- lapply(x_phillips, function(x) c(x, "rate"))
x_names <- sapply(x_with_rate, function(x) paste(x, collapse=' + '))
x_now <- x_with_rate

# two loops, one for the dependent variable, other for the independent variable
rmse <- c()
lambda_phillips <- c()
hh_se_phillips <- c()
nw_se_phillips <- c()
for (y in all_y) {
  print(y)
  for (x in x_now) {
    print(x)
    # define all the dataframes relevant
    df_lag <- lag_df(df_phillips, y, x)
    train_data <- df_lag %>% filter(group <= initial_estimation_period)
    test_data <- df_lag %>% filter(group > initial_estimation_period)
    
    # get forecast
    forecast_values <- ols_predict(train_data, test_data, y, x)
    
    # todo: store the arma11 rmse from previous exercise
    # compute (relative) rmse
    rmse <- c(rmse, sqrt(sum((test_data[y] - forecast_values)^2, na.rm=T)))
    
    # compute 1-lambda
    arma11_forecasts_now <- arma11_forecasts[[y]]     
    reg_formula_lambda <- formula(paste0(y, '~ arma11_forecasts_now + forecast_values'))
    model_lambda <- lm(reg_formula_lambda, data=test_data)
    lambda_phillips <- c(lambda_phillips ,coef(model_lambda)[3])
    # standard-error first with HH-error
    hh_se_phillips <- c(hh_se_phillips ,kernHAC(model_lambda, kernel = "Truncated")[3,3])
    # then with NW-error
    nw_se_phillips <- c(nw_se_phillips, NeweyWest(model_lambda)[3,3])
  }
}

# calculate the relative rmse to arma11
relative_rmse <- rmse/rep(arma11_rmse, each=length(x_names))
# define a list to pass to the function to create tables paper-like
values_estats <- list(relative_rmse, lambda_phillips, hh_se_phillips, nw_se_phillips)
table_term_structure <- create_table_inflation_models(values_estats, all_y, x_names)
print(table_term_structure)

# ---
# now do it for some other specific
# ---
term_structure_x_specific <- list(c('yield'), c('rate', 'yield'), c('gdpg', 'rate', 'yield'))
x_names <- sapply(term_structure_x_specific, function(x) paste(x, collapse=' + '))
x_now <- term_structure_x_specific
rmse <- c()
lambda_phillips <- c()
hh_se_phillips <- c()
nw_se_phillips <- c()
# loop
for (y in all_y) {
  print(y)
  for (x in x_now) {
    print(x)
    # define all the dataframes relevant
    df_lag <- lag_df(df_phillips, y, x)
    train_data <- df_lag %>% filter(group <= initial_estimation_period)
    test_data <- df_lag %>% filter(group > initial_estimation_period)
    
    # get forecast
    forecast_values <- ols_predict(train_data, test_data, y, x)
    
    # todo: store the arma11 rmse from previous exercise
    # compute (relative) rmse
    rmse <- c(rmse, sqrt(sum((test_data[y] - forecast_values)^2, na.rm=T)))
    
    # compute 1-lambda
    arma11_forecasts_now <- arma11_forecasts[[y]]     
    reg_formula_lambda <- formula(paste0(y, '~ arma11_forecasts_now + forecast_values'))
    model_lambda <- lm(reg_formula_lambda, data=test_data)
    lambda_phillips <- c(lambda_phillips ,coef(model_lambda)[3])
    # standard-error first with HH-error
    hh_se_phillips <- c(hh_se_phillips ,kernHAC(model_lambda, kernel = "Truncated")[3,3])
    # then with NW-error
    nw_se_phillips <- c(nw_se_phillips, NeweyWest(model_lambda)[3,3])
  }
}

# calculate the relative rmse to arma11
relative_rmse <- rmse/rep(arma11_rmse, each=length(x_names))
# define a list to pass to the function to create tables paper-like
values_estats <- list(relative_rmse, lambda_phillips, hh_se_phillips, nw_se_phillips)
table_term_structure_specific <- create_table_inflation_models(values_estats, all_y, x_names)
print(table_term_structure_specific)

```

Now for 1995.

```{r phillips_term-structure1995}

# ---
# Run ----
# ---

# change here to change periods (either 1985 or 1995 yet)
initial_estimation_period <- 1995
arma11_rmse <- arma11_rmse1995
arma11_forecasts <- arma11_forecasts1995

# ---
## Phillips models ----
# ---

all_y <- df_phillips %>% select(starts_with('inflation')) %>% colnames()  # "inflation_punew" "inflation_puxhs" "inflation_puxx"  "inflation_pce"
x_phillips <- df_phillips %>% select(gdpg:fac) %>% colnames()  # "gdpg"            "gap1"            "gap2"            "unrate"          "lshr"            "xli"             "xli2"            "fac"

# todo: we need more one loop for the other group: 1995

# two loops, one for the dependent variable, other for the independent variable
rmse <- c()
lambda_phillips <- c()
hh_se_phillips <- c()
nw_se_phillips <- c()
for (y in all_y) {
  print(y)
  for (x in x_phillips) {
    print(x)
    # define all the dataframes relevant
    df_lag <- lag_df(df_phillips, y, x)
    train_data <- df_lag %>% filter(group <= initial_estimation_period)
    test_data <- df_lag %>% filter(group > initial_estimation_period)
    
    # get forecast
    forecast_values <- ols_predict(train_data, test_data, y, x)
    
    # todo: store the arma11 rmse from previous exercise
    # compute (relative) rmse
    rmse <- c(rmse, sqrt(sum((test_data[y] - forecast_values)^2, na.rm=T)))
    
    # compute 1-lambda
    arma11_forecasts_now <- arma11_forecasts[[y]]
    reg_formula_lambda <- formula(paste0(y, '~ arma11_forecasts_now + forecast_values'))
    model_lambda <- lm(reg_formula_lambda, data=test_data)
    lambda_phillips <- c(lambda_phillips ,coef(model_lambda)[3])
    # standard-error first with HH-error
    hh_se_phillips <- c(hh_se_phillips ,kernHAC(model_lambda, kernel = "Truncated")[3,3])
    # then with NW-error
    nw_se_phillips <- c(nw_se_phillips, NeweyWest(model_lambda)[3,3])
  }
}

# calculate the relative rmse to arma11
relative_rmse <- rmse/rep(arma11_rmse, each=length(x_phillips))
# define a list to pass to the function to create tables paper-like
values_estats <- list(relative_rmse, lambda_phillips, hh_se_phillips, nw_se_phillips)
table_ols <- create_table_inflation_models(values_estats, all_y, x_phillips)
print(table_ols)

# ---
# now do it for models with double x's
# ---
doublex_phillips <- list(c('gap1', 'lshr'), c('gap2', 'lshr'))
x_names <- sapply(doublex_phillips, function(x) paste(x, collapse=' + '))
x_now <- doublex_phillips
rmse <- c()
lambda_phillips <- c()
hh_se_phillips <- c()
nw_se_phillips <- c()
# loop
for (y in all_y) {
  print(y)
  for (x in x_now) {
    print(x)
    # define all the dataframes relevant
    df_lag <- lag_df(df_phillips, y, x)
    train_data <- df_lag %>% filter(group <= initial_estimation_period)
    test_data <- df_lag %>% filter(group > initial_estimation_period)
    
    # get forecast
    forecast_values <- ols_predict(train_data, test_data, y, x)
    
    # compute (relative) rmse
    rmse <- c(rmse, sqrt(sum((test_data[y] - forecast_values)^2, na.rm=T)))
    
    # compute 1-lambda
    arma11_forecasts_now <- arma11_forecasts[[y]]     
    reg_formula_lambda <- formula(paste0(y, '~ arma11_forecasts_now + forecast_values'))
    model_lambda <- lm(reg_formula_lambda, data=test_data)
    lambda_phillips <- c(lambda_phillips ,coef(model_lambda)[3])
    # standard-error first with HH-error
    hh_se_phillips <- c(hh_se_phillips ,kernHAC(model_lambda, kernel = "Truncated")[3,3])
    # then with NW-error
    nw_se_phillips <- c(nw_se_phillips, NeweyWest(model_lambda)[3,3])
  }
}

# calculate the relative rmse to arma11
relative_rmse <- rmse/rep(arma11_rmse, each=length(x_names))
# define a list to pass to the function to create tables paper-like
values_estats <- list(relative_rmse, lambda_phillips, hh_se_phillips, nw_se_phillips)
table_ols_2x <- create_table_inflation_models(values_estats, all_y, x_names)
print(table_ols_2x)

# ---
## Term Structure ----
# ---

# basically the same as before, plus rate

all_y <- df_phillips %>% select(starts_with('inflation')) %>% colnames()  # "inflation_punew" "inflation_puxhs" "inflation_puxx"  "inflation_pce"
x_phillips <- df_phillips %>% select(gdpg:fac) %>% colnames()  # "gdpg"            "gap1"            "gap2"            "unrate"          "lshr"            "xli"             "xli2"            "fac"
x_with_rate <- lapply(x_phillips, function(x) c(x, "rate"))
x_names <- sapply(x_with_rate, function(x) paste(x, collapse=' + '))
x_now <- x_with_rate

# two loops, one for the dependent variable, other for the independent variable
rmse <- c()
lambda_phillips <- c()
hh_se_phillips <- c()
nw_se_phillips <- c()
for (y in all_y) {
  print(y)
  for (x in x_now) {
    print(x)
    # define all the dataframes relevant
    df_lag <- lag_df(df_phillips, y, x)
    train_data <- df_lag %>% filter(group <= initial_estimation_period)
    test_data <- df_lag %>% filter(group > initial_estimation_period)
    
    # get forecast
    forecast_values <- ols_predict(train_data, test_data, y, x)
    
    # todo: store the arma11 rmse from previous exercise
    # compute (relative) rmse
    rmse <- c(rmse, sqrt(sum((test_data[y] - forecast_values)^2, na.rm=T)))
    
    # compute 1-lambda
    arma11_forecasts_now <- arma11_forecasts[[y]]     
    reg_formula_lambda <- formula(paste0(y, '~ arma11_forecasts_now + forecast_values'))
    model_lambda <- lm(reg_formula_lambda, data=test_data)
    lambda_phillips <- c(lambda_phillips ,coef(model_lambda)[3])
    # standard-error first with HH-error
    hh_se_phillips <- c(hh_se_phillips ,kernHAC(model_lambda, kernel = "Truncated")[3,3])
    # then with NW-error
    nw_se_phillips <- c(nw_se_phillips, NeweyWest(model_lambda)[3,3])
  }
}

# calculate the relative rmse to arma11
relative_rmse <- rmse/rep(arma11_rmse, each=length(x_names))
# define a list to pass to the function to create tables paper-like
values_estats <- list(relative_rmse, lambda_phillips, hh_se_phillips, nw_se_phillips)
table_term_structure <- create_table_inflation_models(values_estats, all_y, x_names)
print(table_term_structure)

# ---
# now do it for some other specific
# ---
term_structure_x_specific <- list(c('yield'), c('rate', 'yield'), c('gdpg', 'rate', 'yield'))
x_names <- sapply(term_structure_x_specific, function(x) paste(x, collapse=' + '))
x_now <- term_structure_x_specific
rmse <- c()
lambda_phillips <- c()
hh_se_phillips <- c()
nw_se_phillips <- c()
# loop
for (y in all_y) {
  print(y)
  for (x in x_now) {
    print(x)
    # define all the dataframes relevant
    df_lag <- lag_df(df_phillips, y, x)
    train_data <- df_lag %>% filter(group <= initial_estimation_period)
    test_data <- df_lag %>% filter(group > initial_estimation_period)
    
    # get forecast
    forecast_values <- ols_predict(train_data, test_data, y, x)
    
    # todo: store the arma11 rmse from previous exercise
    # compute (relative) rmse
    rmse <- c(rmse, sqrt(sum((test_data[y] - forecast_values)^2, na.rm=T)))
    
    # compute 1-lambda
    arma11_forecasts_now <- arma11_forecasts[[y]]     
    reg_formula_lambda <- formula(paste0(y, '~ arma11_forecasts_now + forecast_values'))
    model_lambda <- lm(reg_formula_lambda, data=test_data)
    lambda_phillips <- c(lambda_phillips ,coef(model_lambda)[3])
    # standard-error first with HH-error
    hh_se_phillips <- c(hh_se_phillips ,kernHAC(model_lambda, kernel = "Truncated")[3,3])
    # then with NW-error
    nw_se_phillips <- c(nw_se_phillips, NeweyWest(model_lambda)[3,3])
  }
}

# calculate the relative rmse to arma11
relative_rmse <- rmse/rep(arma11_rmse, each=length(x_names))
# define a list to pass to the function to create tables paper-like
values_estats <- list(relative_rmse, lambda_phillips, hh_se_phillips, nw_se_phillips)
table_term_structure_specific <- create_table_inflation_models(values_estats, all_y, x_names)
print(table_term_structure_specific)

```


## Brazilian data

Describe data processing


Repeat all models for Brazilian data.

### Time-Series Models

We pick as 2015 as the point of division of our inflation train to test sample. We let our data run up until the first quarter of 2023 (indeed, as the authors, we let our data to be at that frequency, although we have at a monthly frequency). This makes a division of approximately 2/3 (train/test), because we let the data to start to run at 1999 (to avoid periods of hyperinflation and to make all series equally available). We pick three series: IPCA, IPCA-15 and EXFE. However, changing some of those specifications don't lead us to different conclusions.

The models indicate that AR(p) models always perform better than the ARMA(1,1) models by considerable margin.

```{r ts_brazil}

# load data
df_inflation_brazil <- read_csv('brazil_data/df_inflation_brazil.csv') %>% 
  filter(group >= 1999)

# new series!
inflation_series <- c('ipca', 'ipca_15', 'exfe')

# values to store
arma11_rmse_brazil <- c()
arp_rmse_brazil <- c()
arma11_forecasts_brazil <- list()
new_start <- 2015
new_end <- 2023
# same models as previously
for (x in 1:length(inflation_series)) {
  print(inflation_series[x])
  # first the simple rmse values for each inflation series
  arma11_rmse_brazil[x] <- rolling_forecast_arma(df_inflation_brazil, inflation_series[x], initial_end = new_start, final_date = new_end)
  arp_rmse_brazil[x] <- rolling_forecast_ar_p(df_inflation_brazil, inflation_series[x], initial_end = new_start, final_date = new_end)
  
  # we need also the forecasts of the arma11 model to run the lambda models
  arma11_forecasts_brazil[[inflation_series[x]]] <- rolling_forecast_arma(df_inflation_brazil, inflation_series[x], return_rmse = F, initial_end = new_start, final_date = new_end)
}

# printing info
arma11_rmse <- arma11_rmse_brazil
#
# a loop to get values in the way the table is constructed in the paper
just_rmse <- c()
relative_rmse <- c()
for (x in 1:length(arma11_rmse)) {
  just_rmse <- c(just_rmse, arma11_rmse[x], arp_rmse_brazil[x])
  relative_rmse_aux <- c(arma11_rmse[x]/arma11_rmse[x], arp_rmse_brazil[x]/arma11_rmse[x])
  relative_rmse <- c(relative_rmse, relative_rmse_aux)
}
values_estats <- list(just_rmse, relative_rmse)
table_ts_brazil <- create_table_inflation_models(values_estats, inflation_series, c('ARMA', 'AR'), c('RMSE', 'ARMA=1'))
print(table_ts_brazil)

```


### OLS: Phillips Curve + Term Structure Models

Same periods of analysis as in the previous time-series models.

```{r phillips_term-structure_brazil}
# load data
df_inflation_brazil <- read.csv("brazil_data/df_inflation_brazil.csv")
df_realmeasures_brazil <- read.csv("brazil_real_measures_data/df_realmeasures_brazil.csv")

# Prepare data
df_phillips_brazil <- df_inflation_brazil %>%
  left_join(df_realmeasures_brazil) %>% 
  tibble() %>%
  arrange(FirstDate) %>% 
  filter(group <= 2023, group >=1999)

# new definitions
all_y <- c('ipca', 'ipca_15', 'exfe')
x_brazil <- list("gdpg", "gap1", "gap2", "unrate", "lshr", c('gap1', 'lshr'), c('gap2', 'lshr'))
x_names <- sapply(x_brazil, function(x) paste(x, collapse=' + '))
initial_estimation_period <- 2015
arma11_rmse <- arma11_rmse_brazil
arma11_forecasts <- arma11_forecasts_brazil

# the loops for the phillips curve models

# two loops, one for the dependent variable, other for the independent variable
rmse <- c()
lambda_phillips <- c()
hh_se_phillips <- c()
nw_se_phillips <- c()
for (y in all_y) {
  print(y)
  for (x in x_brazil) {
    print(x)
    # define all the dataframes relevant
    df_lag <- lag_df(df_phillips_brazil, y, x)
    train_data <- df_lag %>% filter(group <= initial_estimation_period)
    test_data <- df_lag %>% filter(group > initial_estimation_period)
    
    # get forecast
    forecast_values <- ols_predict(train_data, test_data, y, x)
    
    # todo: store the arma11 rmse from previous exercise
    # compute (relative) rmse
    rmse <- c(rmse, sqrt(sum((test_data[y] - forecast_values)^2, na.rm=T)))
    
    # compute 1-lambda
    arma11_forecasts_now <- arma11_forecasts[[y]]
    reg_formula_lambda <- formula(paste0(y, '~ arma11_forecasts_now + forecast_values'))
    model_lambda <- lm(reg_formula_lambda, data=test_data)
    lambda_phillips <- c(lambda_phillips ,coef(model_lambda)[3])
    # standard-error first with HH-error
    hh_se_phillips <- c(hh_se_phillips ,kernHAC(model_lambda, kernel = "Truncated")[3,3])
    # then with NW-error
    nw_se_phillips <- c(nw_se_phillips, NeweyWest(model_lambda)[3,3])
  }
}

# calculate the relative rmse to arma11
relative_rmse <- rmse/rep(arma11_rmse, each=length(x_brazil))
# define a list to pass to the function to create tables paper-like
values_estats <- list(relative_rmse, lambda_phillips, hh_se_phillips, nw_se_phillips)
table_ols <- create_table_inflation_models(values_estats, all_y, x_names)
print(table_ols)
```

## Critical part

First of all, it would be nice to have a replication package, since this would make verifiability easier (and avoid us the trouble). This is particularly troublesome since the whole point of the paper is to be quantitative, that is, making the best prediction.

However, on top of that, the paper is frequently confusing in terms of the temporal choices for their variables. Probably trying to get more data by using a quaterly frequency, they made the paper more confusing then it would be so by using estimates on an annual basis. Nevertheless, probably in daily forecasting activities data forecast are done more on a quarterly basis, which gives practitioners good advice as how to perform it.

Finally, seasonality ...

Why in the real activity measures we don't let it affect contemporaneously.
