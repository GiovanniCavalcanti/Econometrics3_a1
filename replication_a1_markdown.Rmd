---
title: "Replication Econometrics III -- A1"
author: "Calebe Piacentini and Giovanni"
date: "2024-01-25"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(dplyr)
library(quantmod)
library(forecast)
library(lubridate)
library(gt)
library(tibble)
library(knitr)
library(kableExtra)
```

## What do we need to replicate?

As exposed in the guidelines, we need to replicate all tables and figures **except** for the parts involving models RGM, VAR, RGMVAR, MDL1 and MDL2.

Altering table 2 from the paper to exclude these models, we have:

```{r models}
# Create the data frame
models_table <- data.frame(
 Description = c(
  "Time-series models", # 1
  "", # 2
  "", # 3
  "", # 4
  "Phillips curve (OLS)", # 5
  "", # 6
  "", # 7
  "", # 8
  "", # 9
  "", # 10
  "", # 11
  "", # 12
  "", # 13
  "", # 14
  "OLS term structure models", # 15
  "", # 16
  "", # 17
  "", # 18
  "", # 19
  "", # 20
  "", # 21
  "", # 22
  "", # 23
  "", # 24
  "", # 25
  "Inflation surveys", # 26
  "", # 27
  "", # 28
  "", # 29
  "", # 30
  "", # 31
  "", # 32
  "", # 33
  "" # 34
 ),
 Abbreviation = c(
  "ARMA", # 1
  "AR", # 2
  "RW", # 3
  "AORW", # 4
  "PC1", # 5
  "PC2", # 6
  "PC3", # 7
  "PC4", # 8
  "PC5", # 9
  "PC6", # 10
  "PC7", # 11
  "PC8", # 12
  "PC9", # 13
  "PC10", # 14
  "TS1", # 15
  "TS2", # 16
  "TS3", # 17
  "TS4", # 18
  "TS5", # 19
  "TS6", # 20
  "TS7", # 21
  "TS8", # 22
  "TS9", # 23
  "TS10", # 24
  "TS11", # 25
  "SPF1", # 26
  "SPF2", # 27
  "SPF3", # 28
  "LIV1", # 29
  "LIV2", # 30
  "LIV3", # 31
  "MICH1", # 32
  "MICH2", # 33
  "MICH3" # 34
 ),
 Specification = c(
  "ARMA(1,1)", # 1
  "Autoregressive model", # 2
  "Random walk on quarterly inflation", # 3
  "Random walk on annual inflation", # 4
  "INFL + GDPG", # 5
  "INFL + GAP1", # 6
  "INFL + GAP2", # 7
  "INFL + LSHR", # 8
  "INFL + UNEMP", # 9
  "INFL + XLI", # 10
  "INFL + XLI-2", # 11
  "INFL + FAC", # 12
  "INFL + GAP1 + LSHR", # 13
  "INFL + GAP2 + LSHR", # 14
  "INFL + GDPG + RATETS", # 15
  "INFL + GAP1 + RATETS", # 16
  "INFL + GAP2 + RATETS", # 17
  "INFL + LSHR + RATETS", # 18
  "INFL + UNEMP + RATETS", # 19
  "INFL + XLI + RATETS", # 20
  "INFL + XLI-2 + RATETS", # 21
  "INFL + FAC + RATETS", # 22
  "INFL + SPDTS", # 23
  "INFL + RATE + SPDTS", # 24
  "INFL + GDPG + RATE + SPDT", # 25
  "VAR(1) on RATE, SPD, INFL, GDPG", # 26
  "Linear bias-corrected SPF", # 27
  "Non-linear bias-corrected SPFLIV1", # 28
  "Livingston survey", # 29
  "Linear bias-corrected Livingston", # 30
  "Non-linear bias-corrected Livingston", # 31
  "Michigan survey", # 32
  "Linear bias-corrected Michigan", # 33
  "Non-linear bias-corrected Michigan" # 34
 )
)

knitr::kable(models_table)
```


## Loading Data

Data from the paper.

```{r load_data}

# todo: missing data from real activity
"
FRED:
1. GDP
=> output gap (recursive filters):
  a. GAP1: remove quadratic trend (Gali and Gertler, 1999)
  b. GAP2: HP filter (param_smooth=1600)
2. Unemployment


"

process_inflation_data <- function(file_path, inflation_label, period_column = "Period", label_column = "Label", value_column = "Value") {
  df <- read_csv(file_path) %>%
    select(Period = period_column, Label = label_column, P = value_column) %>%
    mutate(
      DATE = dmy(paste("01", substr(Period, 2, 3), substr(Label, 1, 4), sep = "-")), # Generate DATE column early to use for arrangement
      P_lag = lag(P, n =3), # Create a lagged version of the price column
      !!inflation_label := log(P / P_lag) # Dynamically name the inflation column
    ) %>%
    na.omit() %>%
    arrange(DATE) %>%
    mutate(Quarter = paste(year(DATE), quarter(DATE), sep = "-Q")) %>%
    group_by(Quarter) %>%
    summarise(
      FirstDate = first(DATE),
      FirstP = first(P),
      FirstP_lag = first(P_lag),
      !!inflation_label := first(!!sym(inflation_label))
    ) %>%
    select(Quarter, FirstDate, FirstP, FirstP_lag, !!inflation_label)
}

# Process each dataset
punew_df <- process_inflation_data("data/punew_1947-2023.csv", "inflation_punew")
puxhs_df <- process_inflation_data("data/puxhs_1947-2023.csv", "inflation_puxhs")
puxx_df <- process_inflation_data("data/puxx_1957-2023.csv", "inflation_puxx")

rm(process_inflation_data)

pce_df <- read_csv("data/pce_DPCERD3Q086SBEA_1947-2023.csv") %>%
  rename(P = "DPCERD3Q086SBEA") %>%
  mutate(
    P_lag = lag(P),
    inflation_pce = log(P / P_lag),
    FirstDate = DATE
  ) %>%
  na.omit()


# Merge all dataframes on the DATE column
merged_df <- reduce(list(punew_df, puxhs_df, puxx_df, pce_df), full_join, by = "FirstDate") %>%
  select("FirstDate", contains("inflation")) %>%
  mutate(quarter = paste(year(FirstDate), quarter(FirstDate), sep = "-Q")) 

# write.csv(merged_df, file = "inflation_panel.csv")

rm(pce_df, punew_df, puxhs_df, puxx_df)

## 02.1 Recreate table 1 Summary Statistics - original --------------------------

### Filter the data based on the specified date ranges for each series ----------
punew_puxhs_filter <- filter(merged_df, FirstDate >= as.Date("1952-04-01") & FirstDate <= as.Date("2002-10-01")) %>%
  select("FirstDate", "inflation_punew", "inflation_puxhs", "quarter")
puxx_filter <- filter(merged_df, FirstDate >= as.Date("1958-04-01") & FirstDate <= as.Date("2002-10-01")) %>%
  select("FirstDate", "inflation_puxx", "quarter")
pce_filter <- filter(merged_df, FirstDate >= as.Date("1960-04-01") & FirstDate <= as.Date("2002-10-01")) %>%
  select("FirstDate", "inflation_pce", "quarter")

# Join the dataframes
df_inflation_authors <- full_join(punew_puxhs_filter, puxx_filter, by = "FirstDate") %>%
  full_join(., pce_filter, by = "FirstDate")  %>%
  mutate(group = year(FirstDate)) %>%
  select("FirstDate", "inflation_punew", "inflation_puxhs", "inflation_puxx", "inflation_pce", "quarter" = "quarter.x", "group") 

punew_year <- df_inflation_authors %>%
  group_by(group) %>%
  summarise(punew_year = sum(inflation_punew, na.rm = TRUE))
puxhs_year <- df_inflation_authors %>%
  group_by(group) %>%
  summarise(puxhs_year = sum(inflation_puxhs, na.rm = TRUE))
puxx_year <- df_inflation_authors %>%
  group_by(group) %>%
  summarise(puxx_year = sum(inflation_puxx, na.rm = TRUE))
pce_year <- df_inflation_authors %>%
  group_by(group) %>%
  summarise(pce_year = sum(inflation_pce, na.rm = TRUE))

rm(joined_df, pce_filter, punew_puxhs_filter, puxx_filter)

original_year_df <- full_join(punew_year, puxhs_year, by = "group") %>%
  full_join(., puxx_year, by = "group") %>%
  full_join(., pce_year, by = "group") %>%
  mutate(across(everything(), ~na_if(.x, 0)))
  
rm(pce_year, punew_year, puxhs_year, puxx_year)


```

And now data from Brazil.

## Summary statistics

Here we replicate table 1 of Summary Statistics from the paper and the following figures.

First, we do it for the exactly the period of their analysis. It's worth noting that although their first year of analysis is 1952, PUXX only starts to have data at 1957 (even though they use data starting from 1958).

```{r summary_statistics_data_original}
### Panel A --------------------------------------------------

data_variables <- select(original_year_df, ends_with('year'))

means <- 100*round(colMeans(data_variables, na.rm = T),4)
sds <- data_variables %>% summarise(across(everything(), ~ 100* sd(., na.rm=T)))
autocorrelation_quaterly <- df_inflation_authors %>% 
  select(starts_with("inflation")) %>%
  summarise(across(everything(), ~ cor(., lag(., 4), use='complete.obs'))) %>%
  select("punew_year" = "inflation_punew", "puxhs_year" = "inflation_puxhs", "puxx_year" = "inflation_puxx", "pce_year" = "inflation_pce")
corr_table <- round(cor(data_variables, use = 'complete.obs'), 2)
corr_table[!lower.tri(corr_table)] <- NA

panel_a <- bind_rows(list(means, sds, autocorrelation_quaterly, as.data.frame(corr_table)))
  
# New column to add at the start
statistics_labels <- c("Mean", "Standard deviation", "Autocorrelation", "Correlations", "PUXHS", "PUXX", "PCE")

# Adding the new column at the start of the dataframe
panel_a <- panel_a %>%
  mutate(Statistic = statistics_labels) %>%
  select(Statistic, everything()) %>%
  mutate(across(where(is.numeric), ~ round(., 2)))

# Generate the table 1, panel A (latex code)
kable(panel_a, "latex", booktabs = TRUE, align = 'c', col.names = c("", "PUNEW", "PUXHS", "PUXX", "PCE")) %>%
  kable_styling(latex_options = c("striped", "hold_position")) %>%
  add_header_above(c(" " = 1, "Panel A: 1952:Q2â€“2002:Q4" = 4)) %>%
  pack_rows("Mean", 1, 1) %>%
  pack_rows("Standard deviation", 2, 2) %>%
  pack_rows("Autocorrelation", 3, 3) %>%
  pack_rows("Correlations", 4, 6)

rm(panel_a, sds, means, autocorrelation_quaterly, corr_table, data_variables)

### Panel B -----------------------------------------------

df_inflation_authors_B <- df_inflation_authors %>%
  filter(FirstDate >= "1986-01-01" & FirstDate <= "2002-10-01")

punew_year <- df_inflation_authors_B %>%
  group_by(group) %>%
  summarise(punew_year = sum(inflation_punew, na.rm = TRUE))
puxhs_year <- df_inflation_authors_B %>%
  group_by(group) %>%
  summarise(puxhs_year = sum(inflation_puxhs, na.rm = TRUE))
puxx_year <- df_inflation_authors_B %>%
  group_by(group) %>%
  summarise(puxx_year = sum(inflation_puxx, na.rm = TRUE))
pce_year <- df_inflation_authors_B %>%
  group_by(group) %>%
  summarise(pce_year = sum(inflation_pce, na.rm = TRUE))

original_year_df_B <- full_join(punew_year, puxhs_year, by = "group") %>%
  full_join(., puxx_year, by = "group") %>%
  full_join(., pce_year, by = "group") %>%
  mutate(across(everything(), ~na_if(.x, 0)))

rm(pce_year, punew_year, puxhs_year, puxx_year)

data_variables <- select(original_year_df_B, ends_with('year'))

means <- 100*round(colMeans(data_variables, na.rm = T),4)
sds <- data_variables %>% summarise(across(everything(), ~ 100* sd(., na.rm=T)))
autocorrelation_quaterly <- df_inflation_authors_B %>% 
  select(starts_with("inflation")) %>%
  summarise(across(everything(), ~ cor(., lag(., 4), use='complete.obs'))) %>%
  select("punew_year" = "inflation_punew", "puxhs_year" = "inflation_puxhs", "puxx_year" = "inflation_puxx", "pce_year" = "inflation_pce")
corr_table <- round(cor(data_variables, use = 'complete.obs'), 2)
corr_table[!lower.tri(corr_table)] <- NA

panel_b <- bind_rows(list(means, sds, autocorrelation_quaterly, as.data.frame(corr_table)))

# Adding the new column at the start of the dataframe
panel_b <- panel_b %>%
  mutate(Statistic = statistics_labels) %>%
  select(Statistic, everything()) %>%
  mutate(across(where(is.numeric), ~ round(., 2)))

# Generate the table 1, panel A (latex code)
kable(panel_b, "latex", booktabs = TRUE, align = 'c', col.names = c("", "PUNEW", "PUXHS", "PUXX", "PCE")) %>%
  kable_styling(latex_options = c("striped", "hold_position")) %>%
  add_header_above(c(" " = 1, "Panel B: 1986:Q1â€“ 2002:Q4" = 4)) %>%
  pack_rows("Mean", 1, 1) %>%
  pack_rows("Standard deviation", 2, 2) %>%
  pack_rows("Autocorrelation", 3, 3) %>%
  pack_rows("Correlations", 4, 6)

rm(panel_b, sds, means, autocorrelation_quaterly, corr_table, data_variables)

### Panel C -----------------------------------------------

df_inflation_authors_C <- df_inflation_authors %>%
  filter(FirstDate >= "1996-01-01" & FirstDate <= "2002-10-01")

punew_year <- df_inflation_authors_C %>%
  group_by(group) %>%
  summarise(punew_year = sum(inflation_punew, na.rm = TRUE))
puxhs_year <- df_inflation_authors_C %>%
  group_by(group) %>%
  summarise(puxhs_year = sum(inflation_puxhs, na.rm = TRUE))
puxx_year <- df_inflation_authors_C %>%
  group_by(group) %>%
  summarise(puxx_year = sum(inflation_puxx, na.rm = TRUE))
pce_year <- df_inflation_authors_C %>%
  group_by(group) %>%
  summarise(pce_year = sum(inflation_pce, na.rm = TRUE))

original_year_df_C <- full_join(punew_year, puxhs_year, by = "group") %>%
  full_join(., puxx_year, by = "group") %>%
  full_join(., pce_year, by = "group") %>%
  mutate(across(everything(), ~na_if(.x, 0)))

rm(pce_year, punew_year, puxhs_year, puxx_year)

data_variables <- select(original_year_df_C, ends_with('year'))

means <- 100*round(colMeans(data_variables, na.rm = T),4)
sds <- data_variables %>% summarise(across(everything(), ~ 100* sd(., na.rm=T)))
autocorrelation_quaterly <- df_inflation_authors_C %>% 
  select(starts_with("inflation")) %>%
  summarise(across(everything(), ~ cor(., lag(., 4), use='complete.obs'))) %>%
  select("punew_year" = "inflation_punew", "puxhs_year" = "inflation_puxhs", "puxx_year" = "inflation_puxx", "pce_year" = "inflation_pce")
corr_table <- round(cor(data_variables, use = 'complete.obs'), 2)
corr_table[!lower.tri(corr_table)] <- NA

panel_c <- bind_rows(list(means, sds, autocorrelation_quaterly, as.data.frame(corr_table)))

# Adding the new column at the start of the dataframe
panel_c <- panel_c %>%
  mutate(Statistic = statistics_labels) %>%
  select(Statistic, everything()) %>%
  mutate(across(where(is.numeric), ~ round(., 2)))

# Generate the table 1, panel A (latex code)
kable(panel_c, "latex", booktabs = TRUE, align = 'c', col.names = c("", "PUNEW", "PUXHS", "PUXX", "PCE")) %>%
  kable_styling(latex_options = c("striped", "hold_position")) %>%
  add_header_above(c(" " = 1, "Panel C: 1996:Q1â€“ 2002:Q4" = 4)) %>%
  pack_rows("Mean", 1, 1) %>%
  pack_rows("Standard deviation", 2, 2) %>%
  pack_rows("Autocorrelation", 3, 3) %>%
  pack_rows("Correlations", 4, 6)

rm(panel_c, sds, means, autocorrelation_quaterly, corr_table, data_variables)

rm(df_inflation_authors_B, df_inflation_authors_C, original_year_df_B, original_year_df_C, statistics_labels)
## 0.2.2 Recreate figure 1.A -----------------------------

# Multiply the inflation columns by 100
data_plot1A <- df_inflation_authors %>%
  mutate(across(starts_with("inflation"), ~ .x * 100))

# Pivot the data to a long format for plotting with ggplot2
data_plot1A_long <- data_plot1A %>%
  pivot_longer(cols = starts_with("inflation"), names_to = "inflation_type", values_to = "inflation_value")

# Define linetypes and shapes based on the provided plot image
line_types <- c("solid", "longdash", "dotted", "dotdash")
shapes <- c(NA, NA, NA, 3) # Only the 'Livingston' series uses a shape, represented by pluses

# Create a named vector to map the inflation types to linetypes
names(line_types) <- unique(data_plot1A_long$inflation_type)
names(shapes) <- unique(data_plot1A_long$inflation_type)

# Plot the data
plot_1a <- ggplot(data_plot1A_long, aes(x = FirstDate, y = inflation_value, color = inflation_type, linetype = inflation_type, shape = inflation_type)) +
  geom_line() +
  geom_point(size = 3) +
  scale_color_manual(values = c("black", "black", "black", "black")) +
  scale_linetype_manual(values = line_types) +
  scale_shape_manual(values = shapes) +
  labs(x = "Year", y = "Percentage", title = "Inflation Over Time") +
  theme_minimal() +
  theme(legend.title = element_blank(),
        legend.position = "top",
        axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_x_date(date_breaks = "5 years", date_labels = "%Y") 

plot_1a
# ggsave("inflation_time_series.png", plot_1a, width = 11, height = 8.5)

```
## Estimating the models

### Time-Series Models

Here we'll estimate the ARMA, AR, RW and AORW.

For the forecasts

```{r time_series_models}
# Function to perform rolling window forecasting with ARMA(1,1) over years
rolling_forecast_arma <- function(data, series_name, order_ar=1, order_ma=1, initial_end=as.Date('1985-12-01'), final_date=as.Date('2002-12-01'), window_size=4, return_rmse=T) {
  # adding a forecast vector to store results
  forecasts <- numeric((year(final_date) - year(initial_end))*window_size)
  
  # loop for the rolling window
  for (y in year(initial_end):year(final_date)) {
    train_data <- data %>% filter(FirstDate <= as.Date(str_c(y, '-12-01')))  # Use data up to the current index for training
    train_series <- train_data %>% .[series_name]
    
    # Fit ARMA(1,1) model: yt = mu + phi*yt-1 + epsilon_t + psi*epsilon_{t-1}
    arma_model <- arima(train_series, order = c(order_ar, 0, order_ma))
    # get coefficients + residuals
    phi <- arma_model$coef[1]
    psi <- arma_model$coef[2]
    mu <- arma_model$coef[3]
    residuals <- arma_model$residuals
    
    # Forecast for the next 4 quarters according to equation on paper
    forecast_q <- c()
    for (q in 1:4) {
      forecast_q[q] <- (1/(1-phi)) * (4 - (phi * (1-phi^4))/(1-phi)) * mu + ((phi * (1-phi^4))/(1-phi)) * train_series[nrow(train_series) - (q-1),] + (psi * (1-phi^4))/(1-phi) * residuals[nrow(train_series) - (q-1)]
    }
    
    # just making sure
    forecast_values <- as.numeric(forecast_q)
    # Store forecast values
    forecasts[((y - year(initial_end))*window_size + 1):((y - year(initial_end)+1)*window_size)] <- forecast_values
  }
  
  # decide whether to return forecasts or root mean squared errors (RMSE)
  if (return_rmse) {
    # get data to validate forecasts
    test_series <- data %>% filter(FirstDate > as.Date(initial_end)) %>% .[series_name]
    rmse <- sqrt(sum((test_series - forecasts)^2))
    return(rmse)
  } else{
    return(forecasts)
  }
}

# very similar to the last function, 
# with the difference that now we'll choose AR(p) recursively by SIC
rolling_forecast_ar_p <- function(data, series_name, initial_end=as.Date('1985-12-01'), final_date=as.Date('2002-12-01'), window_size=4, return_rmse=T) {
  # creating a forecast vector to store results
  forecasts <- numeric((year(final_date) - year(initial_end))*window_size)
  
  # loop for the rolling window
  for (y in year(initial_end):year(final_date)) {
    train_data <- data %>% filter(FirstDate <= as.Date(str_c(y, '-12-01')))  # Use data up to the current index for training
    train_series <- train_data %>% select(series_name)
    
    # find best ar order
    ar_order <- best_arma_order(train_series)
    # Fit AR(p) model
    arma_model <- stats::arima(train_series, order = c(ar_order, 0, 0))
    
    # Forecast for the next 4 quarters
    #  ... a little note: here we abstract from the way the paper is doing, since it would imply unecessary complexity (look at the equation for the quarterly forecast in page 1174)
    forecast_values <- as.numeric(forecast(arma_model, h = 4)$mean)
    # Store forecast values
    forecasts[((y - year(initial_end))*window_size + 1):((y - year(initial_end)+1)*window_size)] <- forecast_values
  }
  
  # decide whether to return forecasts or root mean squared errors (RMSE)
  if (return_rmse) {
    # get data to validate forecasts
    test_series <- data %>% filter(FirstDate > as.Date(initial_end)) %>% .[series_name]
    rmse <- sqrt(sum((test_series - forecasts)^2))
    return(rmse)
  } else{
    return(forecasts)
  }
}

# to find the best arma model based on some criteria (still don't contemplate ma orders or other info_criteria than BIC/SIC)
best_arma_order <- function(series, ar_until = 10, ma_order = 0, info_criteria = 'bic'){
  arma_models <- list()
  bic_arma <- c()
  for (p in 1:ar_until) {
    arma_models[[p]] <- arima(series, order = c(p, 0, ma_order))
    # BIC = SIC
    bic_arma[p] <- BIC(arma_models[[p]])
  }
  arma_best_order <- which(min(bic_arma) == bic_arma)
  return(arma_best_order)
}

# running the functions
inflation_series <- merged_df %>% select(starts_with('inflation')) %>% colnames()

arma11_rmse <- c()
arp_rmse <- c()
for (x in 1:length(inflation_series)) {
  arma11_rmse[x] <- rolling_forecast_arma(df_inflation_authors, inflation_series[x])
  arp_rmse[x] <- rolling_forecast_ar_p(df_inflation_authors, inflation_series[x])
}

rolling_forecast_arma(df_inflation_authors, inflation_series[1], return_rmse = T)

```


```{r testes}

model <- arima(df_inflation_authors['inflation_punew'], order = c(1,0,1))
model$coef


data = df_inflation_authors
series_name = 'inflation_punew'
order_ar=1
order_ma=1
initial_end=as.Date('1985-12-01')
final_date=as.Date('2002-12-01')
window_size=4



forecasts <- numeric((year(final_date) - year(initial_end))*window_size)
  
# loop for the rolling window
for (y in year(initial_end):year(final_date)) {
  train_data <- data %>% filter(FirstDate <= as.Date(str_c(y, '-12-01')))
  test_data <- data %>% filter(FirstDate > as.Date(str_c(y, '-12-01')))
  #
  train_series <- train_data %>% select(series_name)
  
  # Fit ARMA(p,q) model
  arma_model <- arima(train_series, order = c(order_ar, 0, order_ma))
  
  # Forecast for the next 4 quarters
  forecast_result <- forecast(arma_model, h = 4)
  
  # Extract the forecasted values for the next 4 quarters
  forecast_values <- as.numeric(forecast_result$mean)
  
  # Store the forecasted values
  forecasts[((y - year(initial_end))*window_size + 1):((y - year(initial_end)+1)*window_size)] <- forecast_values
}

```

